{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import metrics, model_selection\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision.models as models\n",
    "\n",
    "from tqdm.notebook import tqdm, trange\n",
    "import PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sends to CUDA device if available, cpu if not\n",
    "device_str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"using device '{device_str}'\")\n",
    "device = torch.device(device_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation (from deep_learning_2.ipynb)\n",
    "\n",
    "# training data\n",
    "data_transforms = transforms.Compose([ #data augmentation step \n",
    "        #transforms.RandomResizedCrop(224), #random croppings of the image\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.RandomHorizontalFlip(), #mirror image\n",
    "        #transforms.RandomVerticalFlip(), #mirror image\n",
    "        transforms.RandomRotation(10), #rotates image\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# test data\n",
    "data_transforms_test = transforms.Compose([\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) #our new images must match statistics of original data\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loader (from deep_learning_2.ipynb)\n",
    "\n",
    "# OCT images:\n",
    "# train_data = datasets.ImageFolder('/work/meb135/cleandata/train', transform=data_transforms)\n",
    "# test_data = datasets.ImageFolder('/work/meb135/cleandata/test', transform=data_transforms_test)\n",
    "# test_data = datasets.ImageFolder('/work/meb135/cleandata/val', transform=data_transforms_test)\n",
    "\n",
    "# OCTA images:\n",
    "train_data = datasets.ImageFolder('/work/meb135/OCTAcleandata/train', transform=data_transforms)\n",
    "test_data = datasets.ImageFolder('/work/meb135/OCTAcleandata/test', transform=data_transforms_test)\n",
    "# test_data = datasets.ImageFolder('/work/meb135/OCTAcleandata/val', transform=data_transforms_test)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=1, shuffle=True, num_workers=0)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=1, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve, precision_recall_curve\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#notes: good thru resnet, densenet = classifier w/o [-1], \n",
    "modelTypes = ['AlexNet']#, 'VGG', 'ResNet', 'DenseNet', 'GoogleNet']\n",
    "modelArr = ['models.alexnet(pretrained=True)']#, 'models.vgg16(pretrained=True)', \\\n",
    "            #'models.resnet18(pretrained=True)', 'models.densenet161(pretrained=True)', \\\n",
    "            #'models.googlenet(pretrained=True)']\n",
    "modelClass = ['classifierSeq']#, 'classifierSeq', 'fc', 'classifierNSeq', 'fc']\n",
    "modelAcc = []\n",
    "modelAUC = []\n",
    "fprs = []\n",
    "tprs = []\n",
    "recalls = []\n",
    "precisions = []\n",
    "\n",
    "\n",
    "def test_model(m):\n",
    "    preds = []\n",
    "    trues = []\n",
    "    \n",
    "    correct = 0\n",
    "    \n",
    "    total = len(test_data)\n",
    "    model_ft.eval() # set the model into evaluation mode, which changes the \n",
    "    # behavior of the batch norm layer so that it is not sensitive to batch size\n",
    "    with torch.no_grad():\n",
    "        # Iterate through test set minibatchs \n",
    "        for images, labels in tqdm(test_loader, total=len(test_loader)):\n",
    "            # Forward pass\n",
    "            inputs = images.to(device)\n",
    "            labels = labels.unsqueeze(1).to(device)\n",
    "            y = model_ft(inputs)\n",
    "\n",
    "            predictions = torch.round(torch.sigmoid(y)).long()\n",
    "            correct += torch.sum((predictions == labels).float())\n",
    "            \n",
    "            predictions_proba = torch.sigmoid(y)\n",
    "            pred_proba = predictions_proba.cpu().data.numpy()[0][0]\n",
    "\n",
    "            lab=labels.cpu().data.numpy()[0][0]\n",
    "            \n",
    "            trues.append(lab)\n",
    "            preds.append(pred_proba)\n",
    "\n",
    "    fpr, tpr, _ = roc_curve(trues, preds)\n",
    "    auc_score = roc_auc_score(trues, preds)\n",
    "    precision, recall, _ = precision_recall_curve(trues, preds)\n",
    "\n",
    "    fprs.append(fpr)\n",
    "    tprs.append(tpr)\n",
    "    precisions.append(precision)\n",
    "    recalls.append(recall)\n",
    "\n",
    "    accuracy = correct/total\n",
    "    print(f'Test accuracy for {modelTypes[m]}: {accuracy}')\n",
    "    print(f'AUC Score for {modelTypes[m]}: {auc_score}')\n",
    "    \n",
    "    return accuracy, auc_score\n",
    "\n",
    "\n",
    "def train_model(model, criterion, optimizer, m, num_epochs=25):\n",
    "  \n",
    "    for epoch in trange(num_epochs):\n",
    "        print(f'yay epoch {epoch}')\n",
    "        for images, labels in tqdm(train_loader, total=len(train_loader)):\n",
    "            inputs = images.to(device)\n",
    "            labels = labels.float().unsqueeze(1).to(device)\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Do the forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Calculate gradients and step (update parameters)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        model_output = test_model(m)\n",
    "        modelAcc.append(float(model_output[0].cpu().data.numpy()))\n",
    "        modelAUC.append(model_output[1])\n",
    "\n",
    "        model_ft.train() # set model back to training mode (batch norm layers back to normal) after testing\n",
    "\n",
    "# iterate here!!\n",
    "for ind, m in enumerate(modelArr):\n",
    "    model_ft = eval(m)\n",
    "    model_ft.to(device)\n",
    "    \n",
    "    if modelClass[ind] == 'classifierSeq':\n",
    "        num_ftrs = model_ft.classifier[-1].in_features # Need to know # of features coming out of the penultimate layer\n",
    "        model_ft.classifier[-1] = nn.Linear(num_ftrs, 1) # Redefining last feature to predict binary\n",
    "        model_ft.to(device)\n",
    "    \n",
    "    elif modelClass[ind] == 'classifierNSeq':\n",
    "        num_ftrs = model_ft.classifier.in_features # Need to know # of features coming out of the penultimate layer\n",
    "        model_ft.classifier = nn.Linear(num_ftrs, 1) # Redefining last feature to predict binary\n",
    "        model_ft.to(device)\n",
    "    \n",
    "    else:\n",
    "        num_ftrs = model_ft.fc.in_features # Need to know # of features coming out of the penultimate layer\n",
    "        model_ft.fc = nn.Linear(num_ftrs, 1) # Redefining last feature to predict binary\n",
    "        model_ft.to(device)\n",
    "\n",
    "    criterion = nn.BCEWithLogitsLoss() # binary cross entropy loss\n",
    "    optimizer = torch.optim.SGD(model_ft.parameters(), lr=1e-5, momentum=0.9) # momentum smooths the dataset (impacts stochastic gradient descent)\n",
    "\n",
    "    train_model(model_ft, criterion, optimizer, ind, num_epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_test_data = datasets.ImageFolder('/work/meb135/cleandata/test', transform=data_transforms_test)\n",
    "final_test_loader = torch.utils.data.DataLoader(final_test_data, batch_size=1, shuffle=False, num_workers=0)\n",
    "\n",
    "modelAcc_TEST = []\n",
    "modelAUC_TEST = []\n",
    "fprs_TEST = []\n",
    "tprs_TEST = []\n",
    "recalls_TEST = []\n",
    "precisions_TEST = []\n",
    "\n",
    "def final_test_model(m):\n",
    "    preds = []\n",
    "    trues = []\n",
    "    \n",
    "    correct = 0\n",
    "    \n",
    "    total = len(final_test_data)\n",
    "    model_ft.eval() # set the model into evaluation mode, which changes the \n",
    "    # behavior of the batch norm layer so that it is not sensitive to batch size\n",
    "    with torch.no_grad():\n",
    "        # Iterate through test set minibatchs \n",
    "        for images, labels in tqdm(final_test_loader, total=len(final_test_loader)):\n",
    "            # Forward pass\n",
    "            inputs = images.to(device)\n",
    "            labels = labels.unsqueeze(1).to(device)\n",
    "            y = model_ft(inputs)\n",
    "\n",
    "            predictions = torch.round(torch.sigmoid(y)).long()\n",
    "            correct += torch.sum((predictions == labels).float())\n",
    "            \n",
    "            predictions_proba = torch.sigmoid(y)\n",
    "            pred_proba = predictions_proba.cpu().data.numpy()[0][0]\n",
    "\n",
    "            lab=labels.cpu().data.numpy()[0][0]\n",
    "            \n",
    "            trues.append(lab)\n",
    "            preds.append(pred_proba)\n",
    "\n",
    "    fpr, tpr, _ = roc_curve(trues, preds)\n",
    "    auc_score = roc_auc_score(trues, preds)\n",
    "    precision, recall, _ = precision_recall_curve(trues, preds)\n",
    "\n",
    "    fprs_TEST.append(fpr)\n",
    "    tprs_TEST.append(tpr)\n",
    "    precisions_TEST.append(precision)\n",
    "    recalls_TEST.append(recall)\n",
    "\n",
    "    accuracy = correct/total\n",
    "    print(f'Test accuracy: {accuracy}')\n",
    "    print(f'AUC Score: {auc_score}')\n",
    "    \n",
    "    return accuracy, auc_score\n",
    "\n",
    "model_output_TEST = final_test_model(m)\n",
    "modelAcc_TEST.append(float(model_output_TEST[0].cpu().data.numpy()))\n",
    "modelAUC_TEST.append(model_output_TEST[1])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
